{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization\n",
    "\n",
    "The problem we propose to address here is that of __rating prediction__. The data we have is a rating history: ratings of users for items in the interval [1,5] (1 to 5 stars rating). We can put all this data into a sparse matrix called $R$.\n",
    "\n",
    "The matrix $R$ is sparse (more than 99% of the entries are missing), and our goal is to __predict__ the missing entries. One of the solution for this rating prediction is _matrix factorization_. This is fundamentally linked to SVD, which stands for Singular Value Decomposition.\n",
    "\n",
    "Here is the matrix factorization:\n",
    "\n",
    "$R = M\\sum U^T$\n",
    "\n",
    "To be clear, SVD is an algorithm that takes the matrix $R$ as an input, and it gives you $M$, $\\sum$ and $U$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "1. http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/\n",
    "2. http://www.albertauyeung.com/post/python-matrix-factorization/\n",
    "3. https://arxiv.org/pdf/1503.07475.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    Q = Q.T\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i, :], Q[:, j])\n",
    "                    \n",
    "                    for k in range(K):\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        eR = np.dot(P, Q)\n",
    "        e = 0\n",
    "\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i, :], Q[:, j]), 2)\n",
    "\n",
    "                    for k in range(K):\n",
    "                        e = e + (beta / 2) * (pow(P[i][k], 2) + pow(Q[k][j], 2))\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q.T\n",
    "                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.04768771  2.78483412  5.50230144  0.99807947]\n",
      " [ 3.92570891  2.16834716  4.40570898  0.99751618]\n",
      " [ 1.11464726  0.66887894  3.92666805  4.96624064]\n",
      " [ 0.94499662  0.5644064   3.19483872  3.97552371]\n",
      " [ 2.60432914  1.47677322  4.84797291  4.03121858]]\n"
     ]
    }
   ],
   "source": [
    "R = [[5,3,0,1],\n",
    "     [4,0,0,1],\n",
    "     [1,1,0,5],\n",
    "     [1,0,0,4],\n",
    "     [0,1,5,4]]\n",
    "\n",
    "R = np.array(R)\n",
    "\n",
    "N = len(R)\n",
    "M = len(R[0])\n",
    "K = 2\n",
    "\n",
    "# P = np.random.rand(N, K)\n",
    "# Q = np.random.rand(M, K)\n",
    "\n",
    "P = np.array([[ 0.76429108,  0.68098794],\n",
    " [ 0.33121903,  0.56332544],\n",
    " [ 0.00385484,  0.52690095],\n",
    " [ 0.40541877,  0.49737146],\n",
    " [ 0.17445866,  0.52815968]])\n",
    "Q = np.array([[ 0.00909807,  0.57423495],\n",
    " [ 0.57250499,  0.06490164],\n",
    " [ 0.39694569,  0.77008759],\n",
    " [ 0.95925171,  0.1277469 ]])\n",
    "\n",
    "nP, nQ = matrix_factorization(R, P, Q, K)\n",
    "nR = np.dot(nP, nQ.T)\n",
    "print(nR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization:\n",
    "    def __init__(self, R, K, alpha, beta, iterations):\n",
    "        \"\"\"\n",
    "        Perform matrix factorization to predict empty entries in a matrix\n",
    "        \n",
    "        Arguments\n",
    "        - R (ndarray)   : user-item rating matrix\n",
    "        - K (int)       : number of latent dimension\n",
    "        - alpha (float) : learning rate\n",
    "        - beta (float)  : regularization parameter\n",
    "        \"\"\"\n",
    "        \n",
    "        self.R = R \n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        \n",
    "    def train(self):\n",
    "        # Initialize user and item latent feature matrice\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "        \n",
    "        # Initialize the biases\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "        \n",
    "        # Create a list of training samples\n",
    "        self.samples = [\n",
    "            (i, j, self.R[i, j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_items)\n",
    "            if self.R[i, j] > 0\n",
    "        ]\n",
    "        \n",
    "        # Perform stochastic gradient descent for number of iterations\n",
    "        \n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            mse = self.mse()\n",
    "            training_process.append((i, mse))\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print('Iterations: {}; error = {}'.format(i + 1, mse))\n",
    "\n",
    "        return training_process\n",
    "\n",
    "    def mse(self):\n",
    "        \"\"\"\n",
    "        A function to compute the total mean square error\n",
    "        \"\"\"\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            error += pow(self.R[x, y] - predicted[x, y], 2)\n",
    "        return np.sqrt(error)\n",
    "\n",
    "    def sgd(self):\n",
    "        \"\"\"\n",
    "        Perform stochastic gradient descent\n",
    "        \"\"\"\n",
    "        for i, j, r in self.samples:\n",
    "            # Computer prediction and error\n",
    "            prediction = self.get_rating(i, j)\n",
    "            e = (r - prediction)\n",
    "            \n",
    "            # Update bias\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (e - self.beta * self.b_u[j])\n",
    "            \n",
    "            # Update user and item latent feature matrices\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "        \n",
    "    def get_rating(self, i, j):\n",
    "        \"\"\"\n",
    "        Get the predicted rating of user i and item j\n",
    "        \"\"\"\n",
    "        prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j,:].T)\n",
    "        return prediction\n",
    "    \n",
    "    def full_matrix(self):\n",
    "        \"\"\"\n",
    "        Compute the full matrix using the resultant biases, P and Q\n",
    "        \"\"\"\n",
    "        return mf.b + mf.b_u[:, np.newaxis] + mf.b_i[np.newaxis:,] + mf.P.dot(mf.Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 10; error = 0.5795806634257686\n",
      "Iterations: 20; error = 0.177101635232628\n",
      "Iterations: 30; error = 0.06552744650804607\n",
      "Iterations: 40; error = 0.04021978140460307\n",
      "Iterations: 50; error = 0.03464785215202055\n",
      "[[ 4.98860367  2.9978165   3.42637656  1.01050362]\n",
      " [ 3.99547931  2.71239392  3.55887549  1.01087669]\n",
      " [ 1.01188101  0.99702403  5.72188769  4.98428064]\n",
      " [ 1.00909374  0.34626056  4.64210952  3.99514875]\n",
      " [ 1.44227809  1.01402861  4.98933919  3.9982778 ]]\n"
     ]
    }
   ],
   "source": [
    "R = np.array([\n",
    "    [5, 3, 0, 1],\n",
    "    [4, 0, 0, 1],\n",
    "    [1, 1, 0, 5],\n",
    "    [1, 0, 0, 4],\n",
    "    [0, 1, 5, 4],\n",
    "])\n",
    "\n",
    "mf = MatrixFactorization(R, K=2, alpha=0.1, beta=0.01, iterations=50)\n",
    "res = mf.train()\n",
    "print(mf.full_matrix())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
